\begin{comment}

The CWP was coupled with workflow models to create a verification problem suitable for the SPIN model checker. This was accomplished by translating the CWP into an set of LTL properties that together express the same meaning as the CWP. The workflow models can be directly turned into equivalent models in Promela, the input language to SPIN, which is able to prove whether the workflows correctly implement the CWP. Such mechanized and automated reasoning is critical to assurance that the design of a complex distributed system is capable to establish and maintain \emph{actionable risk awareness}. 

The CWP defines thresholds of patient risk during home care and their appropriate actions, thereby making a clear connection from the verified design to its larger, societal purpose of safe care. The interaction between users and AI is only modestly complex, however it strikes the balance needed to illustrate the method with an example workflow that can be followed by readers without much BPMN familiarity. 
The complexity should increase when deployment collects confirmation/dismissal of alerts, and eventual patient outcomes, for AI machine learning to increase alert precision.

Our approach's generality depends on discovery and modeling CWPs. Prior to model-checking CWPs their principles  were applied to human-computer integration for highly usable designs of integrated aircraft mission and maintenance scheduling \cite{workcentered}, joint U.S.-Russia maneuver planning for the \emph{International Space Station}  \cite{10.1145/1978942.1979311}, and health care coordination \cite{BERRY201615}. These CWPs define fundamental requirements for systems that must respond to events outside their direct control. The principles of CWP were recently adopted in the SysML v.2 standard.

Model-checking scalability depends on workflows' number of asynchronous actors, synchronization points, etc. BPMN supports hierarchies of sub-processes for larger workflows, where CWPs may be defined for each; regardless, the case study is a key step towards automation. 

Our current research aims to automate CWP translation to LTL, and BPMN to Promela, so counter-examples from SPIN point directly to CWPs. This undertaking is a non-trivial engineering task as model checking requires domain expertise and the counter-examples produced by SPIN are infinite by virtue of LTL semantics. Ongoing efforts are refining the SPIN translations to include additional global states that correspond directly to CWP states and edges to simplify counter-example mapping. 

Other research under consideration could explore reuse of verified designs in watcher systems that monitor their deployed implementations. CWP models could also be used to derive efficiency measures, e.g., reducing the amount of activity that does not advance the CWP states could be a new approach to efficiency.  

The focus of conventional design methods is on software, which leaves important aspects of system success largely to chance. 
This paper's novel contribution is verifiable integration of human-computer teaming on cognitive tasks. 
The need is industry-wide. 
Expected benefits of verifiable integration include greater safety and reliability of systems for many other critical domains. 

\end{comment}

Workflows have become a regular tool in modern business practices. They have also been increasingly used in the field of LC/NC development. But the efforts to verify workflow execution have been lacking. 

In this paper, we showed that workflows can be translated into verifiable Promela code. That code can then be verified against LTL properties represented by CWPs. This process can and has been automated, and we have provided an implementation for performing automated translation. Our solution uses an intermediate python graph structure and a visitor pattern to generate the Promela model and LTL properties. Additionally, we improve upon the format of the verification results by providing step-by-step annotated images when a verification error occurs. This improvement speeds up and eases the incremental process of modeling correct workflows.

The automated process of verifying BPMN workflows has been tested on three examples as case-studies and two more as scalability exercises. The results show that this method of automated model checking is viable for sizes of workflows frequently seen in LC/NC applications.

There are improvements to be made to the methods described in this paper. First, there should be efforts to conduct a usability study of the automation tool. We are interested not only in the ease of verification, but also in the generated Promela model's readability. Additionally, a usability study should seek to understand the usability of the generated counterexample in finding and fixing BPMN errors.

There should be an effort to further automate the identification of the behavior models. Currently, the behavior models must be manually written by an expert in the workflow's domain. It is our desire that the majority of the behavior models be inferred from different aspects of the BPMN itself. An iterative verification approach could be used: Auto-generated behavior models are tested through verification. After each iteration, verification results are analyzed and behavior models are modified. Additional tools such as AI might also be utilized.

There might also be efforts to explore additional verification properties of interest. For example, there may be a property that enforces eventual existence of valid end states in the BPMN. It may be the case that the BPMN accomplishes the work in the CWP before it reaches an end state itself. This might be undesirable behavior depending on the context.

In order to be usable on many commercial workflows, the tool will need to support many new BPMN elements, especially sub-tasks and call activities. For each of these, there should be support for hierarchical verification. Essentially, the sub-task should be verified independently to behave in the desired way, with its own associated CWP. Then, once we are confident it behaved that way, we can assume that behavior in the behavior models of the parent BPMN workflow. This process has not been implemented into the verification tool at this time.

We would like to compile a larger set of practical test inputs in order to get a more complete view of the tool's limitations and commercial viability. Commercial best modeling practices indicate that workflow scale should not cause problems for the automation tool, but having a large set of working examples would still be desirable.

There may be more effective alternative ways of representing the verification properties. Currently, we are representing them as LTL properties which are supported natively by the model checker we use, SPIN. It may be more efficient, however, to generate never claims directly, since SPIN internally converts each LTL property into never claims anyway.
