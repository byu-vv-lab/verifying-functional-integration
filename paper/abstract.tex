\begin{comment}
Functional integration of human cognition and machine reasoning is an industry-wide problem where failure risks health or safety.
Differences in human versus machine functioning obscure conventional integration. 
We introduce cognitive work problems (CWP) for rigorous, verifiable functional integration. 
CWP specify the cognitive problem that integrated designs must solve. 
They are technology-neutral, abstract work objects, allowing people and computing to share and transform them in coordination.
The end-to-end method is illustrated on a system that employs AI for remote patient monitoring (RPM) during COVID-19 home care. 
The CWP specified \emph{actionable risk awareness} as the medical problem RPM must solve.
Graphical modeling standards enabled user participation: CWP as finite state machines and system behavior in BPMN. 
For model checking, the CWPâ€™s logical content was translated to linear temporal logic (LTL) and the BPMN into Promela as inputs to the SPIN model checker. 
SPIN verified the Promela implements the LTL correctly.
We conclude this CWP-derived RPM design solves the medical problem and enhances patient safety. 
The method appears general to many critical systems.

\end{comment}

Many critical systems industry-wide demand fail-safe process execution. Many of these systems are beginning to use low-code or no-code (LC/NC) solutions to their problems. Mechanisms for verifying the integrity of LC/NC solutions are extremely limited in comparison to traditional code. One solution exhaustively searches the execution state space for undesirable behavior, but it requires expertise in model checking and extensive manual labor. Additionally, error output from that method is exclusively text-based and demands time and familiarity to comprehend. We introduce a tool for automating model checking of LC/NC solutions. Participation in the automation process requires very little knowledge of the underlying model checking tools. We demonstrate the effectiveness of the tool using examples of models including subtle-but-critical errors. We present an extensible model to demonstrate the scalability of the automated verification tool. We also introduce an understandable visual representation of model failures to enable quick iteration on subsequent model versions. The visual representation is critical to understanding why a model doesn't comply with given temporal properties. We conclude that model checking is a viable method for verifying LC/NC systems.
