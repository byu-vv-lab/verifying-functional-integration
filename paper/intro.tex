\begin{comment}

This paper introduces a new method of \emph{model based systems engineering} (MBSE) for functional integration and verification of joint human-computer teaming on cognitive tasks. 
The original contribution to integration is a specification of the abstract, cognitive work problem (CWP) the design must solve \cite{workcentered,BERRY201615,chi2010}, represented as a declarative, computation independent model \cite{Garrido}.
The technical neutrality of this cognitive model makes it a shareable object of abstract work which different types of actors can transform, despite vastly different performance properties.
Thus, a CWP provides the means to integrate the work of a distributed cognitive system that transforms a CWP from its initial state to the goal state required from the system.

The original contribution to design verification reuses the CWP as a new type of required property for model checking to prove the correctness of integrated designs.
The capability to integrate human cognition with machine reasoning and then verify design correctness can increase safety and reliability for a wide range of critical systems.

Our proof-of-technology is illustrated by a case-study of telehealth augmented by \emph{remote patient monitoring} (RPM).
Although telehealth has rapidly gained acceptance for improving accessibility \cite{Medicare} and reducing transmission rates \cite{10.1093/jamia/ocaa067} the remote and asynchronous context of telehealth also introduces risk that patients may deteriorate before physicians can be aware and intervene \cite{10.1097/ALN.0000000000003578}.
The experience of this integrated design process makes clear the difficulty of reasoning about even simple systems without a verification tool.

Bionous \phware\textsuperscript{\textregistered} is an application under development to enhance the telehealth safety of COVID-19 patients with RPM of their vital signs \cite{Phware}.
\phware\ measures and streams seven vital signs: temperature, oxygen saturation, respiration rate, pulse and its variability, and dia/systolic blood pressures.
A single \phware\ ring or finger-clip can be used at home to sense all vital signs in a 60-90 second session, and then send them to a smartphone via Bluetooth.
A smartphone app uploads the data to AI cloud services for storage and machine-learning to assign numerical values to vitals, analyze their trends, and send alerts.
A web-based dashboard displays the trends and alerts to provide clinicians with \emph{actionable risk awareness} of their outpatients.
The streaming of vital signs and alerts serve as an early warning system to maintain cliniciansâ€™ awareness and prioritize their attention, thereby enhancing home care safety.

The following section defines \emph{actionable risk awareness} as the CWP for \phware, developed with clinicians and other experts \footnote{Ann Marie Kimball, an internationally recognized MD epidemiologist in emerging infectious disease, provided medical advice}.
\secref{sec:ltl} details translation of the CWP into \emph{Linear Temporal Logic} (LTL) \cite{10.5555/975331} properties that exactly capture the meaning of the CWP and are suitable for use with a model checker.
%LTL is a first-order predicate calculus with the ability to reason about the temporal ordering of events \cite{10.5555/975331}.
%Any viable design for vital sign RPM of COVID-19 patients must verify against each LTL property created from the CWP in order to claim it takes appropriate action relative to patient risk.
\secref{sec:workflow} presents the \phware\ workflow model in the \emph{Business Process Modeling Notation} (BPMN) \cite{BPMN} that integrates the activities of clinicians, AI cloud services, and patient-caregivers.
\secref{sec:bpmn} details the translation of the workflow into an equivalent \emph{Process Meta-language} (Promela) model for the SPIN model-checker \cite{spin} with \secref{sec:env} discussing how the inputs to the workflow are defined.
The results of the SPIN verification are given in \secref{sec:results}.

The original finite state model, the BPMN model, and full Promela model, with the LTL properties for the CWP, are in a public Github repository \cite{repo}.
The \texttt{README.md} file summarizes its content and how to use SPIN to verify the model.
Figure titles in the electronic version of this manuscript link to equivalent, but larger, more legible versions in GitHub.


% The intentions of the detailed case study are to show the viability of augmenting workflows with CWP for functional integration and model checking, and to illustrate the value for automated reasoning in any design environment.
% SPIN worked effectively and efficiently in this project in terms of performance and iterative design analysis.
% The workflows and CWP revisions were easy to verify when posted, and when SPIN found violations, the accompanying counter-examples provided critical insights to the unexpected, and often overlooked, outcomes common in asynchronous interactions.
% These insights were absolutely necessary for those working on the workflows and those working on the CWP to arrive at the presented final forms.
% The experience of this integrated design process with the model checker makes clear that it is difficult to reliably reason about even simple concurrent systems without a verification tool.
\end{comment}

Low-Code/No-Code (LC/NC) development has been growing rapidly over the last decade. A 2018 survey found that 23\% of global developers used low-code platforms and another 22\% planned to implement them within a year \cite{LowCodeSurvey}. LC/NC solutions have been applied to almost every business field. In many of these fields, there is an expectation for low failure rates due to either safety concerns such as in aeronautics \cite{aeronautics1, aeronautics2}, privacy concerns such as in healthcare \cite{healthcare1, healthcare2}, financial concerns such as in banking \cite{banking1,banking2}, or even concerns about integrity such as in voting \cite{voting1, voting2}. For this reason, there is incentive for solutions to be tested for potential vulnerabilities. Existing methods for debugging and error detection in LC/NC are mostly limited to input testing, static analysis, and symbolic execution \cite{LCTesting, BPMNSimulation1} While these tools are effective in their own right, they fall short particularly in situations with concurrency.

One of the development categories in LC/NC is visual development using process modelling. Business Process Model and Notation (BPMN)\cite{BPMN} is the primary notation for modelling processes in LC/NC visual development \cite{BPMNusage}. BPMN is a notation standardized by the Object Management Group (OMG). It is a graphical notation designed to be both user-friendly and powerful. It has a large range of functional elements that enable a visual description of complex processes with asynchronous execution.

Existing methods of verifying BPMN workflows focus primarily on verifying static properties about the structure of the workflow \cite{bpmnVerification1, bpmnVerification2, ASMverification}. These methods verify properties such as absence of deadlock, fair resource usage, and absence of invalid end states. BPMN workflows are also verified against arbitrary temporal properties in \cite{bpmnVerification3}, but the method fails to verify properties about the object state. A solution in \cite{bpmnVerification4} emphasizes the importance of automating the process of model-based verification, but is limited to testing two BPMN workflows for equivalence. In summary, existing solutions do little to verify important aspects about the work produced by BPMN workflows.

The work in this paper is built upon an existing approach to verify BPMN workflows in \cite{mercer22}, which addresses the object state of the workflow directly. This solution uses model checking to verify a BPMN against an abstract definition of its intended work, provided as a Cognitive Work Problem (CWP). A CWP defines both an object state and a transition system. The work of a CWP is considered accomplished if the object state is transformed in such a way as to follow the transition system through from initial state to a goal state; If a BPMN can accomplish this, it is said to produce the work defined by the CWP. The solution in \cite{mercer22} translates BPMNs and CWPs into Process Meta Language \cite{promelaManual} (ProMeLa) and Linear Temporal Logic \cite{ltl}  (LTL) properties, respectively. The results are input into a model checker to determine whether the BPMN accomplishes the correct work. There are still some unsolved problems, however. First, the existing method is laborious and requires a high degree of expertise in model checking and Promela to use. Second, if there is some error with the workflow during verification, the resulting counterexample is difficult to navigate, even for an expert. This makes iterative model design difficult for the user. 

The work in this paper solves both problems. We introduce an algorithm, with its implementation, to compile a BPMN workflow into a Promela model and a CWP into a set of LTL properties that capture its meaning. We solve several automated reasoning problems relating to the BPMN-to-Promela translation, the CWP-to-LTL translation, and the environment generation. We also introduce a tool that provides visual annotated counterexamples for failed properties. It allows users to step forward and backward through the counterexample path, tracking how the BPMN transforms the object state along the way and observing how that is affecting the CWP state. Our solution drastically decreases the expertise and labor necessary to successfully verify a BPMN workflow and interpret the results. 

\begin{comment}
This work progresses the path toward high-integrity LC/NC solution designs by automating a process which allows BPMN models to be verified against a CWP. The CWP has two parts, an object state and a state machine; the former connects it to the BPMN workflow model. The goal of the verification process is to test whether the BPMN workflow can manipulate the object state toward any of the final states specified by the CWP state machine. Verification must also ensure that the BPMN workflow uses only allowed transitions to reach a final state.
\end{comment}

We evaluate this method as a viable way to verify BPMN functional correctness by using it on five BPMN-CWP benchmark pairs. These benchmarks provide insight into the tool's effectiveness both in model compilation and in its ability to scale reasonably according to process modeling best practices. A survey of over 800 business process models from three companies revealed that the average number of activities in a model is under ten \cite{BPMSizes}. Therefore, this tool was created to handle BPMN models that are reasonably small and would fit on a single page. In some cases, subprocesses and call activites can inject additional complexity in models. In those cases, the parent process is verified in isolation - with each subprocess and call activity mocked to behave as expected. Then, each subprocess and call activity can be verified separately, with its own corresponding CWP. This continues recursively until the entire process of hierarchical verification is complete. We also injected a subtle-but-critical error into one of the examples to both test the tool's capacity to find the issue and also to emphasize the necessity for such a tool to reason about concurrency in a way that is difficult or impossible for most humans. We also provide two extensible examples to show how the tool can scale in two ways: parallel actors and sequential decisions. We compare the results to BPMN modelling best practices provide by top Business Process Management (BPM) companies to show that the tool scales sufficiently.

Absent in our evaluations are any usability studies. This paper is not concerned with the usability of this tool in the hands of a BPMN LC/NC designer. Our evaluation shows that verification can be done, automated and scale to designs that follow general process modelling best practices. We leave the exact operation and managing guidelines, as well as usability investigations, to future work.

Significant contributions in this paper include:
\begin{enumerate}
    \item Automation of a process for verifying BPMN workflows against CWP diagrams referencing object state variables
    \item A counterexample visualization tool that provides step-by-step information about potentially problematic execution paths through the BPMN.
\end{enumerate}

\secref{sec:simpleExample} provides a simple example of a BPMN-CWP pair and shows how model checking can allow us to prove correct implementation.
\secref{sec:background} gives a background of \cite{mercer22} and how it relates to the work in this paper.
\secref{sec:automaticGeneration} looks at the problems and solutions in the task of automating the Promela model generation.
\secref{sec:toolArchitecture} gives an overview of the architecture used in the automation tool.
\secref{sec:counterexample} introduces the counterexample visualization tool, which improves significantly on the prior methods of debugging BPMN workflow errors.
\secref{sec:eval} provides evaluation metrics and the set of examples this tool is evaluated on, and explains the unique performance characteristics of each example.